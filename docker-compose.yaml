version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    volumes:
      - ollama:/root/.ollama
    restart: unless-stopped
    ports:
      - "11434:11434"

  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    depends_on:
      - ollama
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=
    ports:
      - "3000:8080"
    volumes:
      - open-webui:/app/backend/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped

  langflow:
    image: langflowai/langflow:latest
    pull_policy: always
    ports:
      - "7860:7860"
    depends_on:
      - postgres
    environment:
      - LANGFLOW_DATABASE_URL=postgresql://langflow:langflow@postgres:5432/langflow
      - LANGFLOW_CONFIG_DIR=app/langflow
    volumes:
      - langflow-data:/app/langflow

  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: langflow
      POSTGRES_PASSWORD: langflow
      POSTGRES_DB: langflow
    ports:
      - "5432:5432"
    volumes:
      - langflow-postgres:/var/lib/postgresql/data

  litellm:
    image: ghcr.io/berriai/litellm:main-stable
    container_name: litellm
    depends_on:
      - db
    ports:
      - "4000:4000"
    environment:
      - DATABASE_URL=postgresql://llmproxy:dbpassword9090@db:5432/litellm
      - STORE_MODEL_IN_DB=True
    env_file:
      - .env
    volumes:
      - ./litellm_config.yaml:/app/config.yaml
    command: ["--config", "/app/config.yaml"]
    init: true

  db:
    image: postgres
    restart: always
    container_name: litellm-db
    environment:
      POSTGRES_DB: litellm
      POSTGRES_USER: llmproxy
      POSTGRES_PASSWORD: dbpassword9090
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d litellm -U llmproxy"]
      interval: 1s
      timeout: 5s
      retries: 10



  mlflow-db:
    image: postgres:16.2
    environment:
      POSTGRES_DB: mlflowdb
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: password
    ports:
      - "5436:5432"

  mlflow-server:
    build:
      context: ./mlflow/
      dockerfile: Dockerfile
    container_name: mlflow_server
    environment:
      AWS_REGION: eu-west-3
      AWS_DEFAULT_REGION: eu-west-3
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: adminadmin
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
    ports:
      - "5000:5000"
    command: mlflow server --host 0.0.0.0 --workers 1 --backend-store-uri postgresql://mlflow:password@mlflow-db:5432/mlflowdb --default-artifact-root s3://test-bucket/
    depends_on:
      createbuckets:
        condition: service_completed_successfully  # Garante que o bucket seja criado antes

  minio:
    image: minio/minio:RELEASE.2023-12-23T07-19-11Z
    command: server /data --console-address ":9001"
    ports:
      - "9020:9000"
      - "9021:9001"
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: adminadmin
      MINIO_SITE_REGION: eu-west-3

  createbuckets:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      echo sleep 30;
      sleep 30;
      /usr/bin/mc config host add myminio http://minio:9000 admin adminadmin;
      /usr/bin/mc mb myminio/test-bucket || true;
      exit 0;
      "

volumes:
  ollama: {}
  open-webui: {}
  langflow-postgres: {}
  langflow-data: {}